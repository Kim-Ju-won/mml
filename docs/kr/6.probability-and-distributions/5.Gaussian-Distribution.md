---
layout: default
title: 가우시안 분포
lang: kr
lang-ref: Gaussian-Distribution
parent: 확률 분포
permalink: /kr/probability-and-distributions/6-5
nav_order: 5
writer: Minjeong-Yoo
---

# 가우시안 분포
{: .no_toc }

Chapter 5 : Gaussian Distribution
{: .fs-5 .fw-300 }


{% include writer.html writer=page.writer lang=page.lang %}

---

- 목차
    {: .text-gamma }

    1. TOC
    {:toc}

---

가우시안 분포(Gaussian distribution)은 continuous-valued variables 에 대해 가장 널리 알려진 확률분포이다. 이는 normal distribution 이라고도 불린다. 가우시안 분포의 중요성은 계산적인 측면에서 용이한 특성을 많이 가지고 있다는 점에서 비롯되었다. 
머신러닝에서도 마찬가지로 Gaussian processes, variational inference, 강화학습 등에서 가우시안 분포를 많이 사용한다. 뿐만 아니라 signal processing(e.g., Kalman filter), control (e.g.,
linear quadratic regulator) 등 여러 분야에 걸쳐 사용되고 있다. <br><br>

#### [**Gaussian distribution(univariate)**]
Univariate random variable에 대해 가우시안 분포는 다음과 같은 밀도함수를 갖는다.
$$
\begin{align}
p(x|\mu,\sigma^2) = {1 \over \sqrt{2\pi\sigma^2}}exp(-{(x-\mu)^2 \over 2\sigma^2})
\end{align}
$$

#### [**Gaussian distribution(multivariate)**]
Multivariate Gaussian distribution은 mean vector $\mu$와 covariance matrix $\sum$에 의해 특성화되며, 식은 다음과 같다. 

$$
\begin{align}
p(x|\mu,\sum) = (2\pi)^{-{D\over 2}}|\sum|^{-{1 \over 2}}exp(-{1 \over 2}(x - \mu)^T\sum^{-1}(x - \mu))
\end{align}
$$

여기서 $x \in \mathbb{R}^D$ 이다.
$p(x) = \mathcal{N}(x|\mu, \sum)$ 또는 $X \sim \mathcal{N}(\mu, \sum)$로 쓴다. 

![image](https://user-images.githubusercontent.com/59478946/183217656-be9a0e7d-f59f-49e6-aaf4-3b388b84eebe.png)

위 그림은 각각 해당하는 sample에 대한 univariate gaussian과 bivariate gaussian을 보여준다.<br> <br>
평균이 0이고 identity covariance의 특성($\mu = 0, \sum = I$)을 갖는 가우시안 분포의 경우, standard normal distribution이라고 한다. <br> <br>
가우시안 분포는 marginal distribution와 conditional distribution에서 closed-form으로 표현할 수 있어 statistical estimation과 machine learning에서 널리 사용된다. 가우시안 분포는 mean와 covariance 만으로 완벽히 표현할 수 있기 때문에 확률변수의 mean와 covariance에 transformation을 적용하여 transformed distribution을 얻을 수 있다.

## 1. Marginals and Conditionals of Gaussians are Gaussians
일반적인 multivariate random variable 에서의 marginalization과 conditioning 에 대해 다뤄본다. <br>
X와 Y를 차원이 다른 두 개의 multivariate random variable 이라 가정한다. 확률의 sum rule과 conditioning을 다루기 위해 states $[x,y]^T $항의 가우시안 분포를 아래와 같이 표현한다. 
$$
\begin{align}
p(x,y) = \mathcal{N} \begin{pmatrix} \begin{bmatrix} \mu_x \\ \mu_y
\end{bmatrix}, \begin{bmatrix} \sum_{xx} && \sum_{xy} \\
\sum_{yx} && \sum_{yy}
\end{bmatrix}
\end{pmatrix}
\end{align}
$$

여기서 $\sum_{xx} = Cov[x,x], \sum_{yy} = Cov[y,y]$는 각각 x와 y의 marginal covariance matrix 이다. $\sum_{xy} = Cov[x,y]는 x와 y의 cross-covariance matrix 이다. <br> <br>

#### [**Conditioning**]
Conditional distribution $p(x|y)$ 또한 가우시안 분포를 보이며, 다음과 같이 주어진다. 

$$
\begin{align}
p(x,y) = \mathcal{N}(\mu_{x|y}, \sum\nolimits_{x|y}) \\
\mu_{x|y} = \mu_x + \sum\nolimits_{xy}\sum\nolimits_{yy}^T(y-\mu_y) \\
\sum\nolimits_{x|y} = \sum\nolimits_{xx} - \sum\nolimits_{xy}\sum\nolimits_{yy}^{-1}\sum\nolimits_{yx}

\end{align}
$$

<br>

#### [**Conditioning**]
Joint gaussian distribution $p(x,y)$의 marginal distribution $p(x) 또한 가우시안 분포를 보이며 sum rule을 적용하여 다음과 같이 계산한다. 

$$
\begin{align}
p(x) = \int p(x,y)dy = \mathcal{N}(x|\mu_x, \sum\nolimits_{xx})
\end{align}
$$

## 2. Product of Gaussian Densities
Linear regression(chapter 9)에서, 우리는 Gaussian likelihood를 계산할 필요가 있다. 또한 gaussian prior에 대한 가정을 바탕으로, 우리는 Bayes' theorem을 적용하여 likelihood와 prior의 gaussian density 곱의 결과인 posterior를 계산한다. 이는 두 gaussian 분포의 곱인 $\mathcal{N}(x|a, A)\mathcal{N}(x|b, B)$와 같으며, $c \in \mathbb{R}$로 스케일된 가우시안 분포 $c_3\mathcal{N}(x|c_2, c_1) $이다. 

$$
\begin{align}
c_1 = (A^{-1} + B^{-1})^{-1} \\
c_2 = c1(A^{-1}a + B^{-1}b) \\
c_3 = (2\pi)^{-{D \over 2}}{A + B}^{-{1 \over 2}}exp(-{1 \over 2}(a-b)^T(A+B)^{-1}(a-b))
\end{align}
$$

---
<!-- id = [page_num] -->
{% include category.html category=page.parent id=5 %}

```